# Machine Learning

## Overview
The purpose of this project was to analyze the predictive capability of different machine learning algorithms regarding credit risk.

## Results
Six different machine learning algorithms across four different categories were analyzed with the results below, specifically the accuracy, precision, and recall scores.

### Oversampling
- Naive Random Oversampling:
  - Accuracy score was
  - Precision
  - Recall

![Naive Random Accuracy Score](https://raw.githubusercontent.com/jdwrhodes/Credit_Risk_Analysis/main/Module-17-Challenge/resources/naive_random_acc_score.png 'Naive Random Accuracy Score')
![Naive Random Oversampling](https://raw.githubusercontent.com/jdwrhodes/Credit_Risk_Analysis/main/Module-17-Challenge/resources/naive_random_report.png 'Naive Random Oversampling')
- SMOTE: 
  - Accuracy score here 
  - Precision
  - Recall

![SMOTE Accuracy Score](https://raw.githubusercontent.com/jdwrhodes/Credit_Risk_Analysis/main/Module-17-Challenge/resources/smote_acc_score.png 'SMOTE Accuracy Score')
![SMOTE](https://raw.githubusercontent.com/jdwrhodes/Credit_Risk_Analysis/main/Module-17-Challenge/resources/smote_report.png 'SMOTE')

### Undersampling
- Cluster Centroids: 
  - Accuracy score
  - Precision
  - Recall

![Cluster Centroids Accuracy Score](https://raw.githubusercontent.com/jdwrhodes/Credit_Risk_Analysis/main/Module-17-Challenge/resources/cluster_centroid_acc_score.png 'Cluster Accuracy Score')
![Cluster Centroids](https://raw.githubusercontent.com/jdwrhodes/Credit_Risk_Analysis/main/Module-17-Challenge/resources/cluster_centroid_report.png 'Cluster Centroids')

### Over and Undersampling Combination
- SMOTEENN: 
  - Accuracy score
  - Precision
  - Recall

![SMOTEENN Accuracy Score](https://raw.githubusercontent.com/jdwrhodes/Credit_Risk_Analysis/main/Module-17-Challenge/resources/smoteenn_acc_score.png 'SMOTEENN Acurracy Score')
![SMOTEENN](https://raw.githubusercontent.com/jdwrhodes/Credit_Risk_Analysis/main/Module-17-Challenge/resources/smoteenn_report.png 'SMOTEENN')

### Ensemble
- Balanced Random Forest Classifier: 
  - Accuracy score
  - Precision
  - Recall

![Balanced Random Forest Classifier Accuracy Score](https://raw.githubusercontent.com/jdwrhodes/Credit_Risk_Analysis/main/Module-17-Challenge/resources/balanced_rf_acc_score.png 'Balanced Random Forest Classifier Accuracy Score')
![Balanced Random Forest Classifier](https://raw.githubusercontent.com/jdwrhodes/Credit_Risk_Analysis/main/Module-17-Challenge/resources/balanced_rf_report.png 'Balanced Random Forest Classifier')

- Easy Ensemble Classifier: 
  - Accuracy score
  - Precision
  - Recall

![Easy Ensemble Accuracy Score](https://raw.githubusercontent.com/jdwrhodes/Credit_Risk_Analysis/main/Module-17-Challenge/resources/easy_ensemble_acc_score.png 'Easy Ensemble Accuracy Score')
![Easy Ensemble Classifier](https://raw.githubusercontent.com/jdwrhodes/Credit_Risk_Analysis/main/Module-17-Challenge/resources/easy_ensemble_report.png 'Easy Ensemble Classifier')

## Summary


Using bulleted lists, describe the balanced accuracy scores and the precision and recall scores of all six machine learning models. Use screenshots of your outputs to support your results.

Summarize the results of the machine learning models, and include a recommendation on the model to use, if any. If you do not recommend any of the models, justify your reasoning.
